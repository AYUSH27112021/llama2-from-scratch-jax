{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer for LLaMA 2\n",
        "\n",
        "This script handles dataset processing, cleaning, tokenization, and saving tokenized data.\n",
        "It is designed to work with the SentencePiece tokenizer and PyTorch."
      ],
      "metadata": {
        "id": "oVY_HfBUahjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import glob\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "from typing import List\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "import requests\n",
        "import sentencepiece as spm\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tokenizers import Tokenizer"
      ],
      "metadata": {
        "id": "Vp40RsEO4Inq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Authenticate Hugging Face CLI"
      ],
      "metadata": {
        "id": "opPeANXyak8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmUBXOTNcQyS",
        "outputId": "7e5c1af9-c92e-42cb-d6a9-b9e8f0c672ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `keras-gsoc` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `keras-gsoc`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load dataset from Hugging Face"
      ],
      "metadata": {
        "id": "a1ytIXtzam7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"codeparrot/codeparrot-valid-near-deduplication\")\n"
      ],
      "metadata": {
        "id": "IqG3DWiIbyT_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83a16a2-5271-448f-9818-74e34be45bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert dataset into a Pandas DataFrame"
      ],
      "metadata": {
        "id": "T0kE0uS5asFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(ds['train'])"
      ],
      "metadata": {
        "id": "dTXxMKX5dyKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "yVPdQkVSeKtu",
        "outputId": "6caf46f1-f391-4f08-a122-8f2be660935c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         repo_name  \\\n",
              "0              pansapiens/mytardis   \n",
              "1                   twidi/pytyrant   \n",
              "2                HonzaKral/curator   \n",
              "3                   chaubold/hytra   \n",
              "4  makelove/OpenCV-Python-Tutorial   \n",
              "\n",
              "                                          path copies   size  \\\n",
              "0                tardis/apps/mx_views/views.py      3   2892   \n",
              "1                                  pytyrant.py      1  14361   \n",
              "2  test_curator/integration/test_time_based.py      1   1872   \n",
              "3  tests/core/test_conflictingsegmentations.py      1   5839   \n",
              "4            ch21-轮廓Contours/21-findContour.py      1   1096   \n",
              "\n",
              "                                             content       license  \\\n",
              "0  from django.conf import settings\\nfrom django....  bsd-3-clause   \n",
              "1  \"\"\"Pure python implementation of the binary To...           mit   \n",
              "2  from datetime import datetime, timedelta\\n\\nim...    apache-2.0   \n",
              "3  from __future__ import print_function, absolut...           mit   \n",
              "4  # -*- coding: utf-8 -*-\\n\\nimport numpy as np\\...           mit   \n",
              "\n",
              "                  hash  line_mean  line_max  alpha_frac  autogenerated  \n",
              "0 -8726488663588781404  37.052632        79    0.654910          False  \n",
              "1 -5985833604781467244  25.110909       114    0.572871          False  \n",
              "2 -1606032251548790876  40.600000        91    0.634615          False  \n",
              "3 -4230047409174636003  43.572519       125    0.679911          False  \n",
              "4 -2430169206289489120  31.800000       113    0.703252          False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21a331b4-eb8b-4469-ad5c-0b04f2db16bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo_name</th>\n",
              "      <th>path</th>\n",
              "      <th>copies</th>\n",
              "      <th>size</th>\n",
              "      <th>content</th>\n",
              "      <th>license</th>\n",
              "      <th>hash</th>\n",
              "      <th>line_mean</th>\n",
              "      <th>line_max</th>\n",
              "      <th>alpha_frac</th>\n",
              "      <th>autogenerated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pansapiens/mytardis</td>\n",
              "      <td>tardis/apps/mx_views/views.py</td>\n",
              "      <td>3</td>\n",
              "      <td>2892</td>\n",
              "      <td>from django.conf import settings\\nfrom django....</td>\n",
              "      <td>bsd-3-clause</td>\n",
              "      <td>-8726488663588781404</td>\n",
              "      <td>37.052632</td>\n",
              "      <td>79</td>\n",
              "      <td>0.654910</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>twidi/pytyrant</td>\n",
              "      <td>pytyrant.py</td>\n",
              "      <td>1</td>\n",
              "      <td>14361</td>\n",
              "      <td>\"\"\"Pure python implementation of the binary To...</td>\n",
              "      <td>mit</td>\n",
              "      <td>-5985833604781467244</td>\n",
              "      <td>25.110909</td>\n",
              "      <td>114</td>\n",
              "      <td>0.572871</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HonzaKral/curator</td>\n",
              "      <td>test_curator/integration/test_time_based.py</td>\n",
              "      <td>1</td>\n",
              "      <td>1872</td>\n",
              "      <td>from datetime import datetime, timedelta\\n\\nim...</td>\n",
              "      <td>apache-2.0</td>\n",
              "      <td>-1606032251548790876</td>\n",
              "      <td>40.600000</td>\n",
              "      <td>91</td>\n",
              "      <td>0.634615</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chaubold/hytra</td>\n",
              "      <td>tests/core/test_conflictingsegmentations.py</td>\n",
              "      <td>1</td>\n",
              "      <td>5839</td>\n",
              "      <td>from __future__ import print_function, absolut...</td>\n",
              "      <td>mit</td>\n",
              "      <td>-4230047409174636003</td>\n",
              "      <td>43.572519</td>\n",
              "      <td>125</td>\n",
              "      <td>0.679911</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>makelove/OpenCV-Python-Tutorial</td>\n",
              "      <td>ch21-轮廓Contours/21-findContour.py</td>\n",
              "      <td>1</td>\n",
              "      <td>1096</td>\n",
              "      <td># -*- coding: utf-8 -*-\\n\\nimport numpy as np\\...</td>\n",
              "      <td>mit</td>\n",
              "      <td>-2430169206289489120</td>\n",
              "      <td>31.800000</td>\n",
              "      <td>113</td>\n",
              "      <td>0.703252</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21a331b4-eb8b-4469-ad5c-0b04f2db16bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21a331b4-eb8b-4469-ad5c-0b04f2db16bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21a331b4-eb8b-4469-ad5c-0b04f2db16bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-acc23e74-e1dd-47f4-90a6-3b02267b47a3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-acc23e74-e1dd-47f4-90a6-3b02267b47a3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-acc23e74-e1dd-47f4-90a6-3b02267b47a3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6nD17hag5wm",
        "outputId": "a5629d0b-fcab-46e2-fde0-e9ee31d0996b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(110960, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------\n",
        "# Cleaning the dataset\n",
        "# --------------------------------"
      ],
      "metadata": {
        "id": "JJcppuZNkfjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['copies','size',\"license\",\"hash\",\"line_mean\",\"line_max\",\"alpha_frac\",\"autogenerated\"], inplace=True)"
      ],
      "metadata": {
        "id": "-5qpNG1zjxO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## we can keep extract file name and repo-name and keep them as keywords in our dataset"
      ],
      "metadata": {
        "id": "WsibvloalhPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting repository name and file path as keywords"
      ],
      "metadata": {
        "id": "8WAdmurIaztt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_repo_name(string):\n",
        "    return \"\".join(string.split('/')[1:])\n",
        "df['repo_name'] = df['repo_name'].apply(extract_repo_name)\n",
        "def extract_path_name(string):\n",
        "    if('/' not in string):\n",
        "      return string\n",
        "    else:\n",
        "      return \"\".join(string.split('/')[1:])\n",
        "df['path'] = df['path'].apply(extract_path_name)"
      ],
      "metadata": {
        "id": "d5jnHlXVlfcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "pHogx2VznaZY",
        "outputId": "faf4fb7f-18fa-4bdb-e2eb-f560e1cc1e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                repo_name                                               path  \\\n",
              "0                mytardis                               appsmx_viewsviews.py   \n",
              "1                pytyrant                                        pytyrant.py   \n",
              "2                 curator                      integrationtest_time_based.py   \n",
              "3                   hytra               coretest_conflictingsegmentations.py   \n",
              "4  OpenCV-Python-Tutorial                                  21-findContour.py   \n",
              "5         codetransformer                                  teststest_code.py   \n",
              "6    azure-sdk-for-python  resourcesazure-mgmt-resourceazuremgmtresourcel...   \n",
              "7                 sourcer                                 test_salesforce.py   \n",
              "8                timtools                                     sdocfeeders.py   \n",
              "9                   zulip                                       viewshome.py   \n",
              "\n",
              "                                             content  \n",
              "0  from django.conf import settings\\nfrom django....  \n",
              "1  \"\"\"Pure python implementation of the binary To...  \n",
              "2  from datetime import datetime, timedelta\\n\\nim...  \n",
              "3  from __future__ import print_function, absolut...  \n",
              "4  # -*- coding: utf-8 -*-\\n\\nimport numpy as np\\...  \n",
              "5  from dis import dis\\nfrom io import StringIO\\n...  \n",
              "6  # coding=utf-8\\n# ----------------------------...  \n",
              "7  from sourcer import Grammar\\n\\n# This is work ...  \n",
              "8  ## Copyright 2003-2009 Luc Saffre\\n## This fil...  \n",
              "9  from __future__ import absolute_import\\nfrom t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ee2bab3-9f4a-4207-bc57-f5d48d9f62f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo_name</th>\n",
              "      <th>path</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mytardis</td>\n",
              "      <td>appsmx_viewsviews.py</td>\n",
              "      <td>from django.conf import settings\\nfrom django....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pytyrant</td>\n",
              "      <td>pytyrant.py</td>\n",
              "      <td>\"\"\"Pure python implementation of the binary To...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>curator</td>\n",
              "      <td>integrationtest_time_based.py</td>\n",
              "      <td>from datetime import datetime, timedelta\\n\\nim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hytra</td>\n",
              "      <td>coretest_conflictingsegmentations.py</td>\n",
              "      <td>from __future__ import print_function, absolut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>OpenCV-Python-Tutorial</td>\n",
              "      <td>21-findContour.py</td>\n",
              "      <td># -*- coding: utf-8 -*-\\n\\nimport numpy as np\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>codetransformer</td>\n",
              "      <td>teststest_code.py</td>\n",
              "      <td>from dis import dis\\nfrom io import StringIO\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>azure-sdk-for-python</td>\n",
              "      <td>resourcesazure-mgmt-resourceazuremgmtresourcel...</td>\n",
              "      <td># coding=utf-8\\n# ----------------------------...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sourcer</td>\n",
              "      <td>test_salesforce.py</td>\n",
              "      <td>from sourcer import Grammar\\n\\n# This is work ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>timtools</td>\n",
              "      <td>sdocfeeders.py</td>\n",
              "      <td>## Copyright 2003-2009 Luc Saffre\\n## This fil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>zulip</td>\n",
              "      <td>viewshome.py</td>\n",
              "      <td>from __future__ import absolute_import\\nfrom t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ee2bab3-9f4a-4207-bc57-f5d48d9f62f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ee2bab3-9f4a-4207-bc57-f5d48d9f62f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ee2bab3-9f4a-4207-bc57-f5d48d9f62f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0ee73f53-79a7-4f7d-862f-13e535ba4147\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ee73f53-79a7-4f7d-862f-13e535ba4147')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0ee73f53-79a7-4f7d-862f-13e535ba4147 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "EGWMcPBUn9kY",
        "outputId": "0ce69d07-55f4-4f91-db4a-cdc4d9c1740d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "repo_name    0\n",
              "path         0\n",
              "content      0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>repo_name</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>path</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>content</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------\n",
        "# Save dataset as JSON batches\n",
        "# --------------------------------"
      ],
      "metadata": {
        "id": "Mwoa8dnCa3kn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def process_and_dump_json(df, output_folder = 'Dataset', batch_size=2000):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    num_rows = len(df)\n",
        "    num_batches = (num_rows + batch_size - 1) // batch_size\n",
        "\n",
        "    for batch_num in range(num_batches):\n",
        "        start_index = batch_num * batch_size\n",
        "        end_index = min((batch_num + 1) * batch_size, num_rows)\n",
        "\n",
        "        batch_df = df.iloc[start_index:end_index]\n",
        "        batch_data = batch_df.to_dict(orient='records')\n",
        "        filename = os.path.join(output_folder, f\"batch_{batch_num + 1}.json\")\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(batch_data, f, indent=4)  # Use indent for readability\n",
        "\n",
        "        print(f\"Batch {batch_num + 1} dumped to {filename}\")\n",
        "\n",
        "process_and_dump_json(df)"
      ],
      "metadata": {
        "id": "8oM72rbRCFz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#lets convert the dataset to .json file for tokenization"
      ],
      "metadata": {
        "id": "5cl8YI4inoZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def process_and_dump_json(df, batch_size=2000):\n",
        "    num_rows = len(df)\n",
        "    num_batches = (num_rows + batch_size - 1) // batch_size\n",
        "\n",
        "    for batch_num in range(num_batches):\n",
        "        start_index = batch_num * batch_size\n",
        "        end_index = min((batch_num + 1) * batch_size, num_rows)\n",
        "\n",
        "        batch_df = df.iloc[start_index:end_index]\n",
        "        batch_data = batch_df.to_dict(orient='records')\n",
        "        filename = f\"batch_{batch_num + 1}.json\"\n",
        "        with open(filename, 'w') as f:\n",
        "            json.dump(batch_data, f, indent=4)\n",
        "\n",
        "        print(f\"Batch {batch_num + 1} dumped to {filename}\")\n",
        "\n",
        "process_and_dump_json(df)"
      ],
      "metadata": {
        "id": "C2ENF4xhAkyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------\n",
        "# Zip and download dataset\n",
        "# --------------------------------"
      ],
      "metadata": {
        "id": "H2Lu8981RzYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.make_archive('Dataset', 'zip', 'Dataset')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3Y-UN0QEC5lm",
        "outputId": "4d863abf-9e69-4572-b4c0-af6b3e7791f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Dataset.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('Dataset.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EsHIV183DjVH",
        "outputId": "47f325cc-f754-428b-c752-61ab4b0bad90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e261a4ac-8257-44f6-947e-15c7528e3d7a\", \"Dataset.zip\", 221226657)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------\n",
        "# Tokenization using [Sentencepiece](https://github.com/google/sentencepiece)\n",
        "# --------------------------------"
      ],
      "metadata": {
        "id": "bZXGE7rjniVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Dataset.zip -d Dataset"
      ],
      "metadata": {
        "id": "onWW780oNROI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_CACHE_DIR = \"Dataset\"\n",
        "\n",
        "def train_vocab(vocab_size):\n",
        "    \"\"\"\n",
        "    Trains a custom sentencepiece tokenizer on the TinyStories dataset.\n",
        "    The custom tokenizer files will be saved in DATA_CACHE_DIR/tok{N} directories,\n",
        "    where N is the vocab size. This is also where the pretok .bin files will go.\n",
        "    \"\"\"\n",
        "    assert vocab_size > 0, \"Vocab size must be positive\"\n",
        "\n",
        "    # output file prefix path for sentencepiece\n",
        "    prefix = os.path.join(DATA_CACHE_DIR, f\"tok{vocab_size}\")\n",
        "\n",
        "    # how many shards we'll use for vocab training, kept low for usability in colab\n",
        "    num_shards = 10\n",
        "\n",
        "    # 1) export a large chunk of text as a single text file tiny.txt\n",
        "    tiny_file = os.path.join(DATA_CACHE_DIR, \"tiny.txt\")\n",
        "    data_dir = os.path.join(DATA_CACHE_DIR)\n",
        "    shard_filenames = sorted(glob.glob(os.path.join(data_dir, \"*.json\")))\n",
        "\n",
        "    print(f\"Writing temporary file {tiny_file} with {num_shards} shards...\")\n",
        "    with open(tiny_file, \"w\", encoding=\"utf-8\") as of:\n",
        "        for shard in tqdm(shard_filenames[:num_shards]):\n",
        "            with open(shard, \"r\") as f:\n",
        "                data = json.load(f)\n",
        "            for example in data:\n",
        "                text = example[\"content\"]\n",
        "                text = text.strip()\n",
        "                of.write(text + \"\\n\")\n",
        "    print(f\"Size is: {os.path.getsize(tiny_file) / 1024 / 1024:.2f} MB\")\n",
        "\n",
        "    # 2) train the sentencepiece model\n",
        "    print(\"Will now train the vocab...\")\n",
        "    spm.SentencePieceTrainer.train(input=tiny_file,\n",
        "                                   model_prefix=prefix,\n",
        "                                   model_type=\"bpe\",\n",
        "                                   vocab_size=vocab_size,\n",
        "                                   self_test_sample_size=0,\n",
        "                                   input_format=\"text\",\n",
        "                                   character_coverage=1.0,\n",
        "                                   num_threads=os.cpu_count(),\n",
        "                                   split_digits=True,\n",
        "                                   allow_whitespace_only_pieces=True,\n",
        "                                   byte_fallback=True,\n",
        "                                   unk_surface=r\" \\342\\201\\207 \",\n",
        "                                   normalization_rule_name=\"identity\")\n",
        "\n",
        "    # 3) optional cleanup, ask the user if they'd like to delete tiny.txt\n",
        "    dec = input(f\"Delete the temporary file {tiny_file}? [y/N] \")\n",
        "    if dec.lower() == \"y\":\n",
        "        os.remove(tiny_file)\n",
        "        print(f\"Deleted {tiny_file}\")\n",
        "\n",
        "    print(f\"Trained tokenizer is in {prefix}.model\")\n",
        "    print(\"Done.\")\n",
        "\n",
        "\n",
        "def process_shard(args, vocab_size):\n",
        "    shard_id, shard = args\n",
        "    tokenizer_model = get_tokenizer_model_path(vocab_size)\n",
        "    enc = Tokenizer(tokenizer_model)\n",
        "    with open(shard, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    all_tokens = []\n",
        "    for example in tqdm(data, position=shard_id):\n",
        "        text = example[\"content\"]\n",
        "        text = text.strip()  # get rid of leading/trailing whitespace\n",
        "        tokens = enc.encode(text, bos=True, eos=False)  # encode the text, use BOS\n",
        "        all_tokens.extend(tokens)\n",
        "    # convert to uint16 nparray\n",
        "    all_tokens = np.array(all_tokens, dtype=np.uint16)\n",
        "    # calculate the output filename\n",
        "    if vocab_size == 0:\n",
        "        # if we're using Llama 2, just save the tokenized file in the same dir\n",
        "        tokenized_filename = shard.replace(\".json\", \".bin\")\n",
        "    else:\n",
        "        # save .bin files into a new tok{N} directory\n",
        "        bin_dir = os.path.join(DATA_CACHE_DIR, f\"tok{vocab_size}\")\n",
        "        shard_basename = os.path.basename(shard)\n",
        "        bin_basename = shard_basename.replace(\".json\", \".bin\")\n",
        "        tokenized_filename = os.path.join(bin_dir, bin_basename)\n",
        "    # write the bytes\n",
        "    with open(tokenized_filename, \"wb\") as f:\n",
        "        f.write(all_tokens.tobytes())\n",
        "    # calculate the average sequence length (they are separated by BOS=1)\n",
        "    avg_seq_len = all_tokens.size / ((all_tokens == 1).sum())\n",
        "    print(f\"Saved {tokenized_filename}, average seqlen: {avg_seq_len:.2f}\")"
      ],
      "metadata": {
        "id": "3tx_x5q764Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    \n",
        "# --------------------------------\n",
        "# Process dataset for tokenization\n",
        "# --------------------------------"
      ],
      "metadata": {
        "id": "cL4plfbkbZ20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pretokenize(vocab_size):\n",
        "    # iterate the shards and tokenize all of them one by one\n",
        "    data_dir = os.path.join(DATA_CACHE_DIR)\n",
        "    shard_filenames = sorted(glob.glob(os.path.join(data_dir, \"*.json\")))\n",
        "    if vocab_size > 0:\n",
        "        # .bin files will be saved into tok{N} directory, create it once here\n",
        "        bin_dir = os.path.join(DATA_CACHE_DIR, f\"tok{vocab_size}\")\n",
        "        os.makedirs(bin_dir, exist_ok=True)\n",
        "\n",
        "    # process all the shards in a process pool\n",
        "    fun = partial(process_shard, vocab_size=vocab_size)\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        executor.map(fun, enumerate(shard_filenames))\n",
        "    print(\"Done.\")"
      ],
      "metadata": {
        "id": "ADHg92uobXl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --------------------------------\n",
        "# PyTorch Dataset for Pretokenized Data\n",
        "# --------------------------------"
      ],
      "metadata": {
        "id": "0rhGXBIXbjqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PretokDataset(torch.utils.data.IterableDataset):\n",
        "    \"\"\"Loads pretokenized examples from disk and yields them as PyTorch tensors.\"\"\"\n",
        "\n",
        "    def __init__(self, split, max_seq_len, vocab_size, vocab_source):\n",
        "        super().__init__()\n",
        "        self.split = split\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.vocab_size = vocab_size\n",
        "        self.vocab_source = vocab_source\n",
        "\n",
        "    def __iter__(self):\n",
        "        # get worker info within a DataLoader\n",
        "        worker_info = torch.utils.data.get_worker_info()\n",
        "        worker_id = worker_info.id if worker_info else 0\n",
        "        # get DDP rank info\n",
        "        rank = dist.get_rank() if dist.is_initialized() else 0\n",
        "        # combine the worker_id and worker_rank to create a unique seed for rng\n",
        "        seed = 42 + worker_id + 1337 * rank\n",
        "        rng = random.Random(seed)\n",
        "        print(f\"Created a PretokDataset with rng seed {seed}\")\n",
        "        if self.vocab_source == \"llama2\":\n",
        "            # the .bin files are right along the .json files\n",
        "            bin_dir = os.path.join(DATA_CACHE_DIR)\n",
        "            shard_filenames = sorted(glob.glob(os.path.join(bin_dir, \"*.bin\")))\n",
        "        elif self.vocab_source == \"custom\":\n",
        "            # the .bin files are in tok{N} directory\n",
        "            bin_dir = os.path.join(DATA_CACHE_DIR, f\"tok{self.vocab_size}\")\n",
        "            shard_filenames = sorted(glob.glob(os.path.join(bin_dir, \"*.bin\")))\n",
        "        # train/test split. let's use only shard 0 for test split, rest train\n",
        "        shard_filenames = shard_filenames[1:] if self.split == \"train\" else shard_filenames[:1]\n",
        "        assert len(shard_filenames)>0, f\"No bin files found in {bin_dir}\"\n",
        "        while True:\n",
        "            rng.shuffle(shard_filenames)\n",
        "            for shard in shard_filenames:\n",
        "                # open the dataset for reading but keep it on disk with memmap\n",
        "                m = np.memmap(shard, dtype=np.uint16, mode=\"r\")\n",
        "                num_batches = len(m) // self.max_seq_len\n",
        "                num_batches -= 1  # drop the last partial batch\n",
        "                assert num_batches > 0, \"this shard is way too small? investigate.\"\n",
        "                ixs = list(range(num_batches))\n",
        "                rng.shuffle(ixs)\n",
        "                for ix in ixs:\n",
        "                    start = ix * self.max_seq_len\n",
        "                    end = start + self.max_seq_len + 1\n",
        "                    # calling .astype will copy the data into a new numpy array, now in RAM\n",
        "                    chunk = torch.from_numpy((m[start:end]).astype(np.int64))\n",
        "                    x = chunk[:-1]\n",
        "                    y = chunk[1:]\n",
        "                    yield x, y\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# public interface functions\n",
        "\n",
        "def get_tokenizer_model_path(vocab_size):\n",
        "    \"\"\"\n",
        "    Returns path to the sentencepiece tokenizer model for a given vocab size\n",
        "    vocab_size = 0 designates the default Llama 2 tokenizer, in that case\n",
        "    None is returned.\n",
        "    \"\"\"\n",
        "    if vocab_size == 0:\n",
        "        return None\n",
        "    else:\n",
        "        return os.path.join(DATA_CACHE_DIR, f\"tok{vocab_size}.model\")\n",
        "\n",
        "class Task:\n",
        "\n",
        "    @staticmethod\n",
        "    def iter_batches(batch_size, device, num_workers=0, **dataset_kwargs):\n",
        "        ds = PretokDataset(**dataset_kwargs)\n",
        "        dl = torch.utils.data.DataLoader(\n",
        "            ds, batch_size=batch_size, pin_memory=True, num_workers=num_workers\n",
        "        )\n",
        "        for x, y in dl:\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "            yield x, y"
      ],
      "metadata": {
        "id": "PczilKMLbPB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run tokenizer training"
      ],
      "metadata": {
        "id": "fyux1Da7bpAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_vocab(4703)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw72wRRenzH8",
        "outputId": "7b294a74-bf8a-46f2-8c99-23d012659a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing temporary file Dataset/tiny.txt with 10 shards...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  7.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size is: 183.39 MB\n",
            "Will now train the vocab...\n",
            "Delete the temporary file Dataset/tiny.txt? [y/N] y\n",
            "Deleted Dataset/tiny.txt\n",
            "Trained tokenizer is in Dataset/tok4703.model\n",
            "Done.\n"
          ]
        }
      ]
    }
  ]
}